---
title: "Intuition for the probability integral transform"
description: "The probability integral transform states that, for a continuous random variable $X$, the distribution of $F_X(X)$ is $U(0, 1)$. I discuss why this makes sense."
author: "Carson Zhang"
date: "12/04/2023"
draft: false
---

The probability integral transform states that, for a continuous random variable $X$, the distribution of $F_X(X)$ is $U(0, 1)$. This result underlies inverse transform sampling. I suspect that it's also central to why p-values are normally distributed under the null hypothesis. But why does this make sense? Even the existing "intuitive" explanations I have seen are not very convincing.

<!-- I believe this is also why the distribution of p-values is uniform under the null hypothesis. -->

Suppose we have a random sample `x` from some unknown probability distribution. What does $F_X(x)$ look like?

```{r echo=FALSE}
alpha_x = 0.9
beta_x = 3.4
x_seq <- seq(0, 1, length = 100)
x_density <- dbeta(x_seq, alpha_x, beta_x)

plot(x_seq, x_density, type = "l", lty = 1,
     xlab = "X", ylab = "Density", main = "Unknown density of X")
```

Let's try to draw the density of $Y = F_X(x)$ one section at a time.

First, suppose we select the top 3% of the sample. By definition, this comprises the values between the $0.97$ and $1$ $p$-quantiles of this distribution.

```{r echo=FALSE}
quantile_0.97 <- qbeta(0.97, alpha_x, beta_x)
quantile_1 <- 1
```

Here is the density of $X$.

```{r echo=FALSE}
plot(x_seq, x_density, type = "l", lty = 1,
     xlab = "X", ylab = "Unknown density of X", main = "Density of X")
abline(v = c(quantile_0.97, quantile_1), col = "orange")
```

For now, since we don't know what the density of $Y = F_X(X)$ looks like, let's say it's an arbitrary curve.

```{r echo=FALSE}
cdf_seq <- seq(0, 1, length = 10000)

cdf_arbitrary_guess <- (1/4) * sin(2 * pi * cdf_seq) + 1

plot(cdf_seq, cdf_arbitrary_guess, type = "l", xlab = "Y = F(X)", ylab = "Density", main = "Unknown density of Y = F(X)")
abline(v = c(0.97, 1), col = "orange")
```

However, since we selected the top 3% of the probability mass, we know that, within the orange interval, the area under the curve must be $0.03$, and therefore the value of the density must be $1$ on average.

```{r echo=FALSE}
cdf_seq_orange <- seq(0.97, 1, by = 0.0001)
cdf_density_orange <- (1/4) * sin(2 * pi / 0.015 * (cdf_seq_orange - 0.97)) + 1

plot(cdf_seq_orange, cdf_density_orange, type = "l", xlim = c(0, 1), ylim = c(0, 1.5),
     main = "The top 3% of the unknown density of Y", xlab = "Value of the CDF of X", ylab = "Density")
abline(h = mean(cdf_density_orange), col = "orange", lty = "dashed")
abline(v = c(0.97, 1), col = "orange")
```

Now, think about the region between the $0.97$ and $0.98$ p-quantiles of the sample. By definition, this comprises 1% of the probability mass ($0.98 - 0.97 = 0.01$), so we need to adjust our curve to satisfy this condition.

However, we note that all intervals have this same property (even arbitrarily small intervals). It should be natural to suspect the density of curve of the CDF-transformed sample to be a horizontal line at $1$: this is the only function I can think of that guarantees this property. It feels like this can be proven more formally using real analysis.

**Lemma:** For all real numbers $a, b$ such that $0 \leq a < b \leq 1$, $F_X(X) \sim \text{Uniform}(0, 1)$.

**Informal mathematical argument**:

Let $a, b$ be real number such that $0 \leq a < b \leq 1$.

By the argument above, we have $F_Y(b) - F_Y(a) = b - a$.

(Note that we can rewrite this as $F(b) = b \text{ and } F(a) = a$, i.e. $F$ is the identity.)

We have:

$$
\begin{align}
  F_Y(b) - F_Y(a) &= b - a\\
    &= F_Y(Y) \Big|_a^b && \text{(standard antiderivative notation)}\\
    &= \int_a^b f_Y(y)dy && \text{(definition of a probability density function)}\\
    &= \int_a^b 1dy && \text{(a function with the identity as its antiderivative)}\\
\end{align}
$$

So, we have $f_Y(y) = 1$, and therefore, $Y = F_X(x)$ has the standard uniform distribution.

